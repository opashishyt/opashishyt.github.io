# Block all bots and crawlers
User-agent: *
Disallow: /
Disallow: /*.html$
Disallow: /*.js$
Disallow: /*.css$
Disallow: /assets/
Disallow: /js/
Disallow: /css/
Disallow: /protection/
Disallow: /*.apk$
Disallow: /*.zip$
Disallow: /*.rar$
Disallow: /*.7z$
Disallow: /*.tar$
Disallow: /*.gz$

# Block specific bots
User-agent: Googlebot
Disallow: /

User-agent: Googlebot-Image
Disallow: /

User-agent: Googlebot-Video
Disallow: /

User-agent: Bingbot
Disallow: /

User-agent: Slurp
Disallow: /

User-agent: DuckDuckBot
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: YandexImages
Disallow: /

User-agent: facebot
Disallow: /

User-agent: facebookexternalhit
Disallow: /

User-agent: Twitterbot
Disallow: /

User-agent: LinkedInBot
Disallow: /

User-agent: Pinterestbot
Disallow: /

User-agent: TelegramBot
Disallow: /

User-agent: Discordbot
Disallow: /

# Block archive sites
User-agent: archive.org_bot
Disallow: /

User-agent: ia_archiver
Disallow: /

# Block scrapers
User-agent: wget
Disallow: /

User-agent: curl
Disallow: /

User-agent: python
Disallow: /

User-agent: urllib
Disallow: /

# No sitemap
Sitemap: 

# Prevent caching
Cache-Control: no-cache, no-store, must-revalidate
Pragma: no-cache
Expires: 0

# No archive
No-archive: true